{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leejo\\Desktop\\파이썬\\venv-bert_QA_task\\venv\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "from run_train import run_train\n",
    "from run_test import run_test, show_attn_align, get_voice, compare_wav_plot\n",
    "from network import Tacotron\n",
    "from utils import TacotronDataset, collate_fn\n",
    "import hyperparameter as hp\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_files = 'C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron\\\\archive\\\\transcript_ko.txt'\n",
    "with open(text_files, \"rt\", encoding='UTF8') as f:\n",
    "      text = f.readlines()\n",
    "\n",
    "lin_targets = 'C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron\\\\archive\\\\lin_target.npy'\n",
    "mel_targets = 'C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron\\\\archive\\\\mel_target.npy'\n",
    "\n",
    "#check number of files(text, voice)\n",
    "print(\"num_text: %d\", len(text))\n",
    "print(\"num_lin: %d\", len(lin_targets))\n",
    "print(\"num_mel: %d\", len(mel_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#devide data into train, dev, test (8:1:1)\n",
    "train_index = int(len(text) * 0.8)\n",
    "dev_index = int(len(text) * 0.9)\n",
    "\n",
    "text_train = text[:train_index]\n",
    "text_dev = text[train_index:dev_index]\n",
    "text_test = text[dev_index:]\n",
    "\n",
    "lin_train = lin_targets[:train_index]\n",
    "lin_dev = lin_targets[train_index:dev_index]\n",
    "lin_test = lin_targets[dev_index:]\n",
    "\n",
    "mel_train = mel_targets[:train_index]\n",
    "mel_dev = mel_targets[train_index:dev_index]\n",
    "mel_test = mel_targets[dev_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "train_dataset = TacotronDataset(text_train, lin_train, mel_train)\n",
    "dev_dataset = TacotronDataset(text_dev, lin_dev, mel_dev)\n",
    "test_dataset = TacotronDataset(text_test, lin_test, mel_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=hp.batch_size,\n",
    "                              shuffle=True,\n",
    "                              collate_fn= collate_fn)\n",
    "dev_dataloader = DataLoader(dev_dataset,\n",
    "                              batch_size=hp.batch_size,\n",
    "                              collate_fn= collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=hp.batch_size,\n",
    "                              collate_fn= collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = Tacotron()\n",
    "model.to(hp.device)\n",
    "\n",
    "#set optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr = hp.learning_rate, \n",
    "    correct_bias = False\n",
    "    )\n",
    "    \n",
    "#random seed\n",
    "seed_val = 100\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#gradient init\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_code\n",
    "\n",
    "#get test voice\n",
    "\n",
    "#get test attention alignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_train\n",
    "run_train(hp.n_epoch,\n",
    "          model,\n",
    "          optimizer,\n",
    "          hp.device,\n",
    "          train_dataloader,\n",
    "          dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_14604/630936895.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\leejo\\AppData\\Local\\Temp/ipykernel_14604/630936895.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    torch.save(model.state_dict(), 'C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron)\u001b[0m\n\u001b[1;37m                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "#save_model\n",
    "torch.save(model.state_dict(), 'C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron\\\\model\\\\model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model.load_state_dict(torch.load('C:\\\\Users\\\\leejo\\\\Desktop\\\\파이썬\\\\tacotron\\\\model\\\\model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_test\n",
    "run_test(model,\n",
    "         hp.device,\n",
    "         test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose random text, mel data\n",
    "rand_int = random.randint(0, len(text_test)-1)\n",
    "text_random = text_test[rand_int]\n",
    "mel_random = mel_test[rand_int]\n",
    "\n",
    "#get voice\n",
    "voice = get_voice(model, text_random, mel_random)\n",
    "\n",
    "#show attention alignment\n",
    "show_attn_align(model, text_random, mel_random)\n",
    "\n",
    "#compare wav plot\n",
    "#대응되는 original 어떻게 가져올것인가\n",
    "import librosa\n",
    "files = librosa.util.find_files('archive\\kss')\n",
    "audio_random = files[dev_index + rand_int]\n",
    "original, _ = librosa.load(audio_random, sr = hp.sample_rate)\n",
    "compare_wav_plot(model, text_random, mel_random, original, hp.sample_rate)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "830fc09f41f4a8127b783ad2119e0f8b44080ccbdb0580da15d6f44fb7345381"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
